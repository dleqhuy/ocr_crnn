{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qNFX7nzF2SZxfYeeiayzMcWFIRW38cgG",
      "authorship_tag": "ABX9TyNRJlWs1JpiIG87QeM+Y6KD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dleqhuy/ocr_crnn/blob/main/ocr_crnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN1O-SwkvHYj",
        "outputId": "5aaed052-1e96-45a7-c5d2-592198ad0e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ocr_crnn'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 96 (delta 28), reused 82 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (96/96), 670.39 KiB | 11.56 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dleqhuy/ocr_crnn.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r /content/ocr_crnn/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE1bdlH6zJjc",
        "outputId": "a70e3664-3405-40e7-c0fc-82f465881c2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'arabic-reshaper' candidate (version 2.1.3 at https://files.pythonhosted.org/packages/47/27/7b9b824f5342d8ee180027333f2e15842ea36f5bc2d3d24a4e6bb31fb596/arabic_reshaper-2.1.3-py3-none-any.whl#sha256=15078431d8f45eaca0a1710100aabc87abba13759c67eeb4538cca22fe167da1 (from https://pypi.org/simple/arabic-reshaper/))\n",
            "Reason for being yanked: Doesn't work with Python 2\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for diffimg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf \"/content/drive/MyDrive/data.tar.gz\" -C \"/content/sample_data\""
      ],
      "metadata": {
        "id": "6XK_XV9PMNH5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ocr_crnn/crnn/prepare.py \\\n",
        "--config ocr_crnn/configs/text_recognition.yml \\\n",
        "--dir /content/sample_data"
      ],
      "metadata": {
        "id": "vM5RgJhjzHK-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ocr_crnn/crnn/train.py \\\n",
        "--config ocr_crnn/configs/text_recognition.yml \\\n",
        "--save_dir /content/drive/MyDrive/ocr_exp1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCMPUVps2EgL",
        "outputId": "f97dc9ca-adc5-4eae-93d7-3d86afef3d68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-21 06:46:10.655288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-21 06:46:11.635541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-21 06:46:11.635649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-21 06:46:11.635669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "{'batch_size_per_replica': 128,\n",
            " 'dataset_builder': {'channel': 1,\n",
            "                     'img_height': 32,\n",
            "                     'img_width': 200,\n",
            "                     'vocab_path': 'ocr_crnn/configs/vocab.txt'},\n",
            " 'earlystopping': {'patience': 2},\n",
            " 'epochs': 10,\n",
            " 'fit_verbose': 1,\n",
            " 'tensorboard': {'histogram_freq': 1, 'profile_batch': 0},\n",
            " 'train_csv_path': 'ocr_crnn/configs/df_train.csv',\n",
            " 'val_csv_path': 'ocr_crnn/configs/df_val.csv'}\n",
            "2023-02-21 06:46:16.629001: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Model: \"crnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 200, 32, 1)]      0         \n",
            "                                                                 \n",
            " Conv1 (Conv2D)              (None, 200, 32, 32)       320       \n",
            "                                                                 \n",
            " pool1 (MaxPooling2D)        (None, 100, 16, 32)       0         \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 100, 16, 64)       18496     \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 50, 8, 64)         0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 50, 512)           0         \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 50, 64)            32832     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 64)            0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 256)          197632    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 50, 128)          164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " logits (Dense)              (None, 50, 64)            8256      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421,888\n",
            "Trainable params: 421,888\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "743/743 [==============================] - 64s 62ms/step - loss: 30.2552 - sequence_accuracy: 0.0000e+00 - val_loss: 26.5356 - val_sequence_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "743/743 [==============================] - 44s 59ms/step - loss: 13.9920 - sequence_accuracy: 0.1230 - val_loss: 3.7732 - val_sequence_accuracy: 0.5636\n",
            "Epoch 3/10\n",
            "743/743 [==============================] - 42s 56ms/step - loss: 3.8512 - sequence_accuracy: 0.5237 - val_loss: 1.5808 - val_sequence_accuracy: 0.7778\n",
            "Epoch 4/10\n",
            "743/743 [==============================] - 42s 57ms/step - loss: 2.2420 - sequence_accuracy: 0.6769 - val_loss: 0.8837 - val_sequence_accuracy: 0.8542\n",
            "Epoch 5/10\n",
            "743/743 [==============================] - 44s 59ms/step - loss: 1.5507 - sequence_accuracy: 0.7521 - val_loss: 0.5736 - val_sequence_accuracy: 0.8978\n",
            "Epoch 6/10\n",
            "743/743 [==============================] - 40s 54ms/step - loss: 1.1639 - sequence_accuracy: 0.7976 - val_loss: 0.4508 - val_sequence_accuracy: 0.9110\n",
            "Epoch 7/10\n",
            "743/743 [==============================] - 40s 54ms/step - loss: 0.9494 - sequence_accuracy: 0.8258 - val_loss: 0.3583 - val_sequence_accuracy: 0.9266\n",
            "Epoch 8/10\n",
            "743/743 [==============================] - 41s 56ms/step - loss: 0.7870 - sequence_accuracy: 0.8487 - val_loss: 0.3474 - val_sequence_accuracy: 0.9258\n",
            "Epoch 9/10\n",
            "743/743 [==============================] - 42s 56ms/step - loss: 0.6709 - sequence_accuracy: 0.8665 - val_loss: 0.2671 - val_sequence_accuracy: 0.9424\n",
            "Epoch 10/10\n",
            "743/743 [==============================] - 40s 54ms/step - loss: 0.5797 - sequence_accuracy: 0.8804 - val_loss: 0.2286 - val_sequence_accuracy: 0.9502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ocr_crnn/crnn/predict.py  \\\n",
        "--config ocr_crnn/configs/text_recognition.yml  \\\n",
        "--weight /content/drive/MyDrive/ocr_exp1/10_0.2286_0.9502.h5 \\\n",
        "--images /content/ocr_crnn/example/images  \\\n",
        "--post greedy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdKezRWWd_W1",
        "outputId": "6d3b1741-cb44-4f30-e2cc-774c7acfde57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-21 06:58:05.734540: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-21 06:58:07.408800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-21 06:58:07.408925: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-21 06:58:07.408945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-21 06:58:10.506103: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Path: /content/ocr_crnn/example/images/detector_2.jpg, y_pred: ['detector'], probability: [0.9993256]\n",
            "Path: /content/ocr_crnn/example/images/paraproctitis_7.jpg, y_pred: ['paraproctitis'], probability: [0.99910504]\n",
            "Path: /content/ocr_crnn/example/images/Lindgren_5.jpg, y_pred: ['Lindgren'], probability: [0.9624358]\n",
            "Path: /content/ocr_crnn/example/images/twice-charged_9.jpg, y_pred: ['twice-charged'], probability: [0.995047]\n",
            "Path: /content/ocr_crnn/example/images/Tindale_1.jpg, y_pred: ['Tindale'], probability: [0.9937869]\n",
            "Path: /content/ocr_crnn/example/images/rhotacistic_4.jpg, y_pred: ['rhotacistic'], probability: [0.99500376]\n",
            "Path: /content/ocr_crnn/example/images/encephala_6.jpg, y_pred: ['encephala'], probability: [0.9985802]\n",
            "Path: /content/ocr_crnn/example/images/fissive_8.jpg, y_pred: ['fissive'], probability: [0.9954051]\n",
            "Path: /content/ocr_crnn/example/images/microphagous_0.jpg, y_pred: ['microphagous'], probability: [0.99475896]\n",
            "Path: /content/ocr_crnn/example/images/propretorial_3.jpg, y_pred: ['propretorial'], probability: [0.9986227]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swaZM_2vw93O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}